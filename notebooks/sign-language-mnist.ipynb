{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "import kagglehub\n",
    "datamunge_sign_language_mnist_path = kagglehub.dataset_download('datamunge/sign-language-mnist')\n",
    "\n",
    "print('Data source import complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-12T22:34:30.855939Z",
     "iopub.status.busy": "2025-04-12T22:34:30.855632Z",
     "iopub.status.idle": "2025-04-12T22:34:32.172724Z",
     "shell.execute_reply": "2025-04-12T22:34:32.171411Z",
     "shell.execute_reply.started": "2025-04-12T22:34:30.855913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):                                        # SOLO PARA KAGGLE\n",
    "for dirname, _, filenames in os.walk(datamunge_sign_language_mnist_path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "n_jobs = -1 # number of jobs to run in parallel\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo los datos y los separo en desarrollo y evaluación final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval = pd.read_csv(r'C:\\Users\\aaron\\.cache\\kagglehub\\datasets\\datamunge\\sign-language-mnist\\versions\\1\\sign_mnist_test\\sign_mnist_test.csv')\n",
    "data_dev = pd.read_csv(r'C:\\Users\\aaron\\.cache\\kagglehub\\datasets\\datamunge\\sign-language-mnist\\versions\\1\\sign_mnist_train\\sign_mnist_train.csv').sample(frac=1, random_state=28)\n",
    "X_eval, y_eval = data_eval.iloc[:, 1:], data_eval.iloc[:, 0]\n",
    "X_dev, y_dev = data_dev.iloc[:, 1:], data_dev.iloc[:, 0]\n",
    "X_dev.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion auxiliar\n",
    "def graficar_fila(row, ax, label=None):\n",
    "    n = int(np.sqrt(len(row)))\n",
    "    ax.imshow(row.values.reshape(n, n), cmap='gray')\n",
    "    if label is not None:\n",
    "        ax.set_title(label, fontsize='small')\n",
    "    ax.axis('off')\n",
    "\n",
    "leters = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y'}\n",
    "\n",
    "fig, axs = plt.subplots(nrows=5, ncols=5, figsize=(6, 6))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    X_dev_i = X_dev[y_dev == i]\n",
    "    if X_dev_i.shape[0] > 0:\n",
    "        graficar_fila(X_dev_i.iloc[0], ax=ax, label=leters[i])\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "fig.suptitle('Ejemplos de cada seña')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proporcion de cada letra en el dataset de desarrollo\n",
    "count = y_dev.value_counts().sort_index()\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.barplot(x=[leters.get(i, '?') for i in count.index], y=count.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos estan balanceados, no hay necesidad de hacer stratified sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X_dev.shape[0] == X_dev.value_counts().shape[0]: # no hay duplicados en el dataset de desarrollo\n",
    "    print('No hay duplicados en el dataset de desarrollo')\n",
    "else:\n",
    "    print('Hay duplicados en el dataset de desarrollo, limpiar el dataset para evitar filtacion de datos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un modelo simple\n",
    "Arbol de profundidad maxima 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "X_dev_train, X_dev_test, y_dev_train, y_dev_test = train_test_split(X_dev, y_dev, test_size=0.3, random_state=28)\n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=28)\n",
    "tree.fit(X_dev_train, y_dev_train)\n",
    "y_dev_pred = tree.predict(X_dev_test)\n",
    "\n",
    "print('Accuracy con test: ', accuracy_score(y_dev_test, y_dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos donde caen las features (pixeles) mas importantes para este modelo, ello veamos como se distribuyen. Esto nos dara un cota inferior razonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 3))\n",
    "sns.boxplot(tree.feature_importances_)\n",
    "plt.title('Importancia de los pixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixeles_mas_importantes = X_dev.columns[tree.feature_importances_ > 0.015] # cota elegida a ojo\n",
    "\n",
    "fig, axs = plt.subplots(nrows=5, ncols=5, figsize=(6, 6))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    X_dev_i = X_dev[y_dev == i]\n",
    "    if X_dev_i.shape[0] > 0:\n",
    "        row = X_dev_i.iloc[0]\n",
    "        row[pixeles_mas_importantes] = 0 # en negro\n",
    "        graficar_fila(row, ax=ax, label=leters[i])\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "fig.suptitle('Ejemplos de cada seña')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que la mayoría de ellos se ubican sobre los dedos y contornos de la mano, lo que indica que el modelo está aprendiendo patrones coherentes con las diferencias morfológicas entre las clases. En algunos casos, como en las letras \"C\" o \"L\", los píxeles relevantes están claramente alineados con la forma característica del gesto, lo que refuerza la interpretación de que el modelo está focalizando en información útil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validacion cruzada con 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'auprc': 'average_precision',\n",
    "    'roc_auc': 'roc_auc_ovr'\n",
    "}\n",
    "\n",
    "scores = cross_validate(DecisionTreeClassifier(max_depth=10), X_dev_test, y_dev_test, cv=5, scoring=scoring, n_jobs=n_jobs)\n",
    "\n",
    "print(scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean scores for each metric\n",
    "accuracy_scores = scores['test_accuracy']\n",
    "auprc_scores = scores['test_auprc']\n",
    "roc_auc_scores = scores['test_roc_auc']\n",
    "\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "mean_auprc = np.mean(auprc_scores)\n",
    "mean_roc_auc = np.mean(roc_auc_scores)\n",
    "\n",
    "# Creating a DataFrame for scores\n",
    "scores_df = pd.DataFrame({\n",
    "    'Fold': range(1, len(accuracy_scores) + 1),\n",
    "    'Accuracy': accuracy_scores,\n",
    "    'AUPRC': auprc_scores,\n",
    "    'ROC AUC OneVSRest': roc_auc_scores\n",
    "})\n",
    "\n",
    "# Adding the mean row\n",
    "mean_row = pd.DataFrame({\n",
    "    'Fold': ['Mean'],\n",
    "    'Accuracy': [mean_accuracy],\n",
    "    'AUPRC': [mean_auprc],\n",
    "    'ROC AUC OneVSRest': [mean_roc_auc]\n",
    "})\n",
    "scores_df = pd.concat([scores_df, mean_row], ignore_index=True)\n",
    "\n",
    "# Displaying the table\n",
    "print(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados muestran que el modelo tiene un desempeño bastante flojo: la accuracy ronda el 50% y el AUPRC también es bajo. Aunque el ROC AUC por clase está un poco mejor (~0.85). En general, parece que el modelo no distingue bien entre las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparacion de algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos RandomizedSearchCV con Arboles de decision, KNN y SVM. Usamos como metrica de performance accuracy ya que tenemo un dataset balanceado (por lo menos los de desarrollo). Vale la pena aclarar que accuracy es de las peor metricas para evaluar un modelo, pero no existe un consenso una metrica integral para el clasificacion multiclase, además es la metrica que usa kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "tree_param_grid = {\n",
    "    'max_depth': range(1,90), 'criterion': ['gini', 'entropy'],\n",
    "    'random_state':[28]\n",
    "}\n",
    "\n",
    "knn_param_grid = {\n",
    "    'n_neighbors': range(1,50)\n",
    "}\n",
    "\n",
    "svm_param_grid = {\n",
    "    'C': np.logspace(-4, 2, 20),\n",
    "    'random_state':[28]\n",
    "}\n",
    "\n",
    "rscv_tree = RandomizedSearchCV(DecisionTreeClassifier(), tree_param_grid, n_iter=10, cv=5, scoring='accuracy', n_jobs=n_jobs, random_state=28)\n",
    "rscv_knn = RandomizedSearchCV(KNeighborsClassifier(), knn_param_grid, n_iter=10, cv=5, scoring='accuracy', n_jobs=n_jobs, random_state=28)\n",
    "rscv_svm = RandomizedSearchCV(SVC(), svm_param_grid, n_iter=10, cv=5, scoring='accuracy', n_jobs=n_jobs, random_state=28)\n",
    "\n",
    "rscv_tree.fit(X_dev_train, y_dev_train)\n",
    "print('Mejores hiperparametros para arbol de decision: ', rscv_tree.best_params_)\n",
    "print('         Accuracy: ', rscv_tree.best_score_)\n",
    "print()\n",
    "\n",
    "rscv_knn.fit(X_dev_train, y_dev_train)\n",
    "print('Mejores hiperparametros para KNN: ', rscv_knn.best_params_)\n",
    "print('         Accuracy: ', rscv_knn.best_score_)\n",
    "print()\n",
    "\n",
    "rscv_svm.fit(X_dev_train, y_dev_train)\n",
    "print('Mejores hiperparametros para SVM: ', rscv_svm.best_params_)\n",
    "print('         Accuracy: ', rscv_svm.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos que tal LDA y Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "scores_LDA = cross_val_score(LinearDiscriminantAnalysis(), X_dev_train, y_dev_train, cv=4, n_jobs=n_jobs, scoring='accuracy')\n",
    "print('Cross validation scores for LDA:', scores_LDA)\n",
    "print('         Mean:', scores_LDA.mean())\n",
    "print()\n",
    "\n",
    "for func in [naive_bayes.GaussianNB, naive_bayes.MultinomialNB]:\n",
    "    scores = cross_val_score(func(), X_dev_train, y_dev_train, cv=4, n_jobs=n_jobs, scoring='accuracy')\n",
    "    print(f'Cross validation scores for {func.__name__}:', scores)\n",
    "    print('            Mean:', scores.mean())\n",
    "    print()\n",
    "\n",
    "scores_RF = cross_val_score(RandomForestClassifier(random_state=28), X_dev_train, y_dev_train, cv=4, n_jobs=n_jobs, scoring='accuracy')\n",
    "print('Cross validation scores for RandomForest:', scores_RF)\n",
    "print('         Mean:', scores_RF.mean())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sesgo y varianza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudiaremos mas a fondo el mejor arbol, Random Forest, SVM y Linear discriminant analysis (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas de complejidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curva(model, X_train, X_test, y_train, y_test, param :str, steps):\n",
    "    sub_train_error = []\n",
    "    test_error = []\n",
    "    for i in steps:\n",
    "        model2 = model(**{param: i, 'random_state': 28})\n",
    "        model2.fit(X_train, y_train)\n",
    "        sub_train_error.append(1 - accuracy_score(y_train, model2.predict(X_train)))\n",
    "        test_error.append(1 - accuracy_score(y_test, model2.predict(X_test)))\n",
    "    return sub_train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "cant = 10\n",
    "max_complex = 50\n",
    "steps = np.arange(1, max_complex, max_complex//cant, dtype=int)\n",
    "y_1, y_2 = curva(DecisionTreeClassifier, X_dev_train, X_dev_test, y_dev_train, y_dev_test, 'max_depth', steps)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(steps, y_1, label=\"Train error\")\n",
    "plt.plot(steps, y_2, label=\"Train error\")\n",
    "plt.title(\"Arbol\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"1 - accuracy\")\n",
    "plt.ylim((0,1))\n",
    "plt.legend()\n",
    "\n",
    "y_1, y_2 = curva(RandomForestClassifier, X_dev_train, X_dev_test, y_dev_train, y_dev_test, 'n_estimators', steps)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(steps, y_1, label=\"Train error\")\n",
    "plt.plot(steps, y_2, label=\"Test error\")\n",
    "plt.title(\"RandomForestClassifier\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"1 - accuracy\")\n",
    "plt.ylim((0,1))\n",
    "plt.legend()\n",
    "\n",
    "steps = np.linspace(1e-4, 120, cant)\n",
    "y_1, y_2 = curva(SVC, X_dev_train, X_dev_test, y_dev_train, y_dev_test, 'C', steps)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(steps, y_1, label=\"Train error\")\n",
    "plt.plot(steps, y_2, label=\"Test error\")\n",
    "plt.title(\"SVM\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"1 - accuracy\")\n",
    "plt.ylim((0,1))\n",
    "plt.legend()\n",
    "\n",
    "plt.suptitle('Curvas de complejidad')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas curvas de complejidad muestran cómo varía el error (medido como \\(1 - \\text{accuracy}\\)) en el conjunto de entrenamiento y test a medida que se incrementa la complejidad del modelo, según un hiperparámetro característico:\n",
    "\n",
    "- **Árbol de Decisión:** Se observa una clara mejora en el desempeño al aumentar `max_depth` hasta cierto punto, donde ambos errores convergen, esto sugiere que el modelo ha alcanzado un punto de sobreajuste.\n",
    "- **Random Forest:** A medida que se incrementa el número de árboles (`n_estimators`), el error disminuye rápidamente, estabilizándose con un rendimiento sólido tanto en entrenamiento como en test.\n",
    "- **SVM:** El parámetro `C` controla la penalización por errores de clasificación. Para valores bajos, el modelo subajusta fuertemente (altos errores). A partir de \\(C $\\sim$ 0.2\\), el modelo logra ajustar correctamente, alcanzando un mínimo error de generalización.\n",
    "\n",
    "Estas curvas no solo permiten comparar modelos, sino también entender el comportamiento de cada uno frente a la complejidad y cómo responden al ajuste de hiperparámetros clave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def curva_de_aprendizaje(model, X_train, X_test, y_train, y_test):\n",
    "    sub_train_error = []\n",
    "    test_error = []\n",
    "    for i in np.linspace(800, len(X_dev_train), 8, dtype=int):\n",
    "        X_train_i = X_train.iloc[:i,:]\n",
    "        y_train_i = y_train.iloc[:i]\n",
    "        X_test_i  =  X_test.iloc[:i,:]\n",
    "        y_test_i  =  y_test.iloc[:i]\n",
    "        model2 = deepcopy(model)\n",
    "        model2.fit(X_train_i, y_train_i)\n",
    "        sub_train_error.append(1 - accuracy_score(y_train_i, model2.predict(X_train_i)))\n",
    "        test_error.append(1 - accuracy_score(y_test_i, model2.predict(X_test_i)))\n",
    "    return sub_train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(800, len(X_dev_train), 5)\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "y_1, y_2 = curva_de_aprendizaje(DecisionTreeClassifier(**rscv_tree.best_params_), X_dev_train, X_dev_test, y_dev_train, y_dev_test)\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.plot(x, y_1, label=\"Train error\")\n",
    "plt.plot(x, y_2, label=\"Test error\")\n",
    "plt.title(\"Arbol\")\n",
    "plt.xlabel(\"Tamanio train\")\n",
    "plt.ylabel(\"1 - accuracy\")\n",
    "plt.ylim((0,1))\n",
    "plt.legend()\n",
    "\n",
    "y_1, y_2 = curva_de_aprendizaje(RandomForestClassifier(random_state=28), X_dev_train, X_dev_test, y_dev_train, y_dev_test)\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.plot(x, y_1, label=\"Train error\")\n",
    "plt.plot(x, y_2, label=\"Test error\")\n",
    "plt.title(\"RandomForestClassifier\")\n",
    "plt.xlabel(\"Tamanio train\")\n",
    "plt.ylabel(\"1 - accuracy\")\n",
    "plt.ylim((0,1))\n",
    "plt.legend()\n",
    "\n",
    "y_1, y_2 = curva_de_aprendizaje(SVC(**rscv_svm.best_params_), X_dev_train, X_dev_test, y_dev_train, y_dev_test)\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.plot(x, y_1, label=\"Train error\")\n",
    "plt.plot(x, y_2, label=\"Test error\")\n",
    "plt.title(\"SVM\")\n",
    "plt.xlabel(\"Tamanio train\")\n",
    "plt.ylabel(\"1 - accuracy\")\n",
    "plt.ylim((0,1))\n",
    "plt.legend()\n",
    "\n",
    "y_1, y_2 = curva_de_aprendizaje(LinearDiscriminantAnalysis(), X_dev_train, X_dev_test, y_dev_train, y_dev_test)\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.plot(x, y_1, label=\"Train error\")\n",
    "plt.plot(x, y_2, label=\"Test error\")\n",
    "plt.title(\"LDA\")\n",
    "plt.xlabel(\"Tamanio train\")\n",
    "plt.ylabel(\"1 - accuracy\")\n",
    "plt.ylim((0,1))\n",
    "plt.legend()\n",
    "\n",
    "plt.suptitle('Curvas de aprendizaje')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las curvas de aprendizaje permiten analizar el comportamiento del error a medida que se incrementa el tamaño del conjunto de entrenamiento. Se presentan las curvas para cuatro modelos: Árbol de Decisión, Random Forest, SVM y LDA. En el eje \\(x\\) se muestra el tamaño del conjunto de entrenamiento, y en el eje \\(y\\), el error (\\(1 - \\text{accuracy}\\)) para entrenamiento y test.\n",
    "\n",
    "- **Árbol de Decisión:** El error de entrenamiento se mantiene cercano a cero, mientras que el error de test disminuye progresivamente con más datos. Esto sugiere un modelo con baja varianza pero cierto sesgo.\n",
    "- **Random Forest:** Se logra un excelente desempeño con mas de una cuarta parte de los datos. El error de test converge rápidamente a un valor muy bajo, indicando robustez y buena generalización.\n",
    "- **SVM:** También muestra una rápida convergencia del error de test, confirmando su capacidad de generalizar bien, probablemente gracias a la separación que logra el kernel gaussiano.\n",
    "- **LDA:** Presenta un comportamiento similar a SVM, aunque su rendimiento es levemente inferior. Su naturaleza lineal parece ser suficiente para capturar bien la estructura de los datos en este caso.\n",
    "\n",
    "En todos los casos, la brecha entre los errores de entrenamiento y test se reduce con mayor cantidad de datos, lo cual es un buen indicio de que los modelos no están sobreajustando. Además, se evidencia que más datos contribuyen a una mejora en la generalización.\n",
    "\n",
    "A medida que aumenta el tamaño del conjunto de entrenamiento, la diferencia entre el error de entrenamiento y el de test tiende a reducirse, lo cual sugiere que los modelos están logrando una buena capacidad de generalización. En general, se observa que disponer de más datos tiene un efecto positivo en el desempeño de los modelos sobre datos no vistos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion de performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elijo SVM como modelo final, ya que es el que mejor desempeño tiene en el conjunto de test. Aun así, la diferencia con Random Forest no es significativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = SVC(**rscv_svm.best_params_)\n",
    "best.fit(X_dev, y_dev)\n",
    "y_pred = best.predict(X_eval)\n",
    "\n",
    "print('Accuracy con los datos de evaluacion: ', accuracy_score(y_eval, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_eval, y_pred, display_labels=[leters[i] for i in leters.keys()],\n",
    "    ax=ax, cmap='Blues', colorbar=False\n",
    ")\n",
    "\n",
    "plt.title('Matriz de confusión')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3258,
     "sourceId": 5337,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
